{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_strategies.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP25ARZhwDe2qidZc3I+HOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visith1577/tensorflow_advanced/blob/main/training_strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5WxJdv4jd3B"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y1dmJLajn6L",
        "outputId": "971b7051-0287-4441-847e-9cabb9059b9f"
      },
      "source": [
        "datasets, info = tfds.load(\"mnist\", with_info=True, download=True, as_supervised=True, data_dir=\"./data\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ./data/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset mnist downloaded and prepared to ./data/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxZe71DLkAwl"
      },
      "source": [
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5SjxIQkIlR",
        "outputId": "40755838-800b-49f3-81c2-48ee528412f5"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R2HTEpNk40I"
      },
      "source": [
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "# Use for Mirrored Strategy\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2re3aVY2licI"
      },
      "source": [
        "@tf.function \n",
        "def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E__6LbWclonC"
      },
      "source": [
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_691EwFVltmg"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agN6nVO2ly81",
        "outputId": "70ea5821-66c2-4f36-d83c-0b8f9be7a22c"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhcDM_eAl1IJ",
        "outputId": "0e6362f7-d585-4325-9ed0-224875679068"
      },
      "source": [
        "model.fit(train_dataset, epochs=12)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 [==============================] - 49s 16ms/step - loss: 0.2039 - accuracy: 0.9403\n",
            "Epoch 2/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0694 - accuracy: 0.9796\n",
            "Epoch 3/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0482 - accuracy: 0.9858\n",
            "Epoch 4/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0349 - accuracy: 0.9895\n",
            "Epoch 5/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0273 - accuracy: 0.9916\n",
            "Epoch 6/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0203 - accuracy: 0.9941\n",
            "Epoch 7/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0165 - accuracy: 0.9947\n",
            "Epoch 8/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0115 - accuracy: 0.9966\n",
            "Epoch 9/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0095 - accuracy: 0.9969\n",
            "Epoch 10/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0071 - accuracy: 0.9979\n",
            "Epoch 11/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0075 - accuracy: 0.9978\n",
            "Epoch 12/12\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0052 - accuracy: 0.9983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff53f57ae50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCHHdUtvmi2_"
      },
      "source": [
        "<h1> Multi GPU </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41XWm22umiVa",
        "outputId": "0ce7364f-ceb8-45cc-9304-c2770f1f824d"
      },
      "source": [
        "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
        "\n",
        "# If the list of devices is not specified in the\n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
        "# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n",
        "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGGL0uaQm2Cz"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07VivASRl3VO"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Adding a dimension to the array -> new shape == (28, 28, 1)\n",
        "# We are doing this because the first layer in our model is a convolutional\n",
        "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
        "# batch_size dimension will be added later on.\n",
        "train_images = train_images[..., None]\n",
        "test_images = test_images[..., None]\n",
        "\n",
        "# Normalize the images to [0, 1] range.\n",
        "train_images = train_images / np.float32(255)\n",
        "test_images = test_images / np.float32(255)\n",
        "\n",
        "# Batch the input data\n",
        "BUFFER_SIZE = len(train_images)\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\n",
        "# Create Datasets from the batches\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
        "\n",
        "# Create Distributed Datasets from the datasets\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOioQniwmvbM"
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx40IKGfm5nB"
      },
      "source": [
        "with strategy.scope():\n",
        "    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n",
        "    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n",
        "    # Remember -- the map reduce is how the losses get aggregated\n",
        "    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def compute_loss(labels, predictions):\n",
        "        # Compute Loss uses the loss object to compute the loss\n",
        "        # Notice that per_example_loss will have an entry per GPU\n",
        "        # so in this case there'll be 2 -- i.e. the loss for each replica\n",
        "        per_example_loss = loss_object(labels, predictions)\n",
        "        # You can print it to see it -- you'll get output like this:\n",
        "        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
        "        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
        "        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n",
        "        print(per_example_loss)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "    # We'll just reduce by getting the average of the losses\n",
        "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "    # Accuracy on train and test will be SparseCategoricalAccuracy\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "    # Optimizer will be Adam\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    # Create the model within the scope\n",
        "    model = create_model()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vn0YpGUm88r"
      },
      "source": [
        "# `run` replicates the provided computation and runs it\n",
        "# with the distributed input.\n",
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs):\n",
        "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
        "  #tf.print(per_replica_losses.values)\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "def train_step(inputs):\n",
        "  images, labels = inputs\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = compute_loss(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_accuracy.update_state(labels, predictions)\n",
        "  return loss\n",
        "\n",
        "#######################\n",
        "# Test Steps Functions\n",
        "#######################\n",
        "@tf.function\n",
        "def distributed_test_step(dataset_inputs):\n",
        "  return strategy.run(test_step, args=(dataset_inputs,))\n",
        "\n",
        "def test_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss.update_state(t_loss)\n",
        "  test_accuracy.update_state(labels, predictions)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ufT1zLnAy8",
        "outputId": "208b524f-7d96-4199-aeeb-79789c138937"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  # Do Training\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for batch in train_dist_dataset:\n",
        "    total_loss += distributed_train_step(batch)\n",
        "    num_batches += 1\n",
        "  train_loss = total_loss / num_batches\n",
        "\n",
        "  # Do Testing\n",
        "  for batch in test_dist_dataset:\n",
        "    distributed_test_step(batch)\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n",
        "\n",
        "  print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n",
        "\n",
        "  test_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
            "Epoch 1, Loss: 0.507211446762085, Accuracy: 82.05833435058594, Test Loss: 0.4026782810688019, Test Accuracy: 85.41999816894531\n",
            "Epoch 2, Loss: 0.34027618169784546, Accuracy: 87.7066650390625, Test Loss: 0.3498190641403198, Test Accuracy: 87.06999969482422\n",
            "Epoch 3, Loss: 0.29609546065330505, Accuracy: 89.30332946777344, Test Loss: 0.3026416003704071, Test Accuracy: 89.31000518798828\n",
            "Epoch 4, Loss: 0.26353511214256287, Accuracy: 90.34833526611328, Test Loss: 0.27620384097099304, Test Accuracy: 90.02999877929688\n",
            "Epoch 5, Loss: 0.2390468567609787, Accuracy: 91.22833251953125, Test Loss: 0.30874454975128174, Test Accuracy: 89.2300033569336\n",
            "Epoch 6, Loss: 0.22031176090240479, Accuracy: 91.89833068847656, Test Loss: 0.2775426506996155, Test Accuracy: 89.76000213623047\n",
            "Epoch 7, Loss: 0.20168879628181458, Accuracy: 92.51000213623047, Test Loss: 0.26195642352104187, Test Accuracy: 90.8499984741211\n",
            "Epoch 8, Loss: 0.186375230550766, Accuracy: 93.19499969482422, Test Loss: 0.25828003883361816, Test Accuracy: 90.69999694824219\n",
            "Epoch 9, Loss: 0.17138388752937317, Accuracy: 93.75333404541016, Test Loss: 0.25794678926467896, Test Accuracy: 91.06999969482422\n",
            "Epoch 10, Loss: 0.1575596183538437, Accuracy: 94.16999816894531, Test Loss: 0.2732871472835541, Test Accuracy: 90.83000183105469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyZTzE0xnDZx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}